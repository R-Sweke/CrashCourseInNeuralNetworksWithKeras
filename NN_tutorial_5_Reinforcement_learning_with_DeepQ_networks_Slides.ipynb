{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Crash Course on Neural Networks with Keras Part 5 - Deep-Q Reinforcement Learning\n",
    "\n",
    "Finally, lets shift gears and talk about reinforcement learning. This is of course by now a huge field and we will be deliberately brief and only scratch the surface. For more depth, rigour and context, I strongly suggest this excellent [textbook](http://incompleteideas.net/book/bookdraft2018mar11.pdf).\n",
    "\n",
    "So, what is Reinforcement learning?\n",
    "\n",
    "In general, we imagine the setting of an Agent interacting with some Environment in discrete time steps:\n",
    "\n",
    "<img src=\"images/EnvironmentAgent.png\",width=350,height=350>\n",
    "\n",
    "Very roughly, at each time step the agent is in some \"state\" $S_t$ - which could be a combination of its knowledge of the environment, its historical actions, and some internal variables, and it must then choose a valid action $A_t$ (or way of interacting with the environment). In response to this action, the environment changes and provides the agent with a scalar reward $R_{t+1}$ and a boolean signal which indicates whether the game is over (i.e. whether the agent fails/dies/loses). The agent then updates its state based on new information from the environment, and the loop continues. The goal of the agent is to learn how to act in such a way that maximizes the *expected discounted cumulative reward* it obtains (to be defined properly below). Note, that typically the way that the agent chooses its action, the way that the environment is effected by the action, and the reward that is generated can all be stochastic, and that in the context of finite state and action spaces this process can be formalized within the framework of finite Markov decision processes (FMDP) :\n",
    "\n",
    "$$p(s',r|s,a) \\equiv \\mathrm{pr}(S_t = s',R_t = r|S_{t-1} = s, A_{t-1} = a)$$\n",
    "\n",
    "There are by now many approaches to solving this problem, and many different algorithms. However, we will focus on an algorthim called \"Deep-Q learning\". Famously, this algorithm enabled agents to obtain human level performace on a variety of [Atari games](https://www.nature.com/articles/nature14236). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a) A brief introduction to Deep-Q learning\n",
    "\n",
    "We present a vanilla version of the algorithm used in this [Atari paper](https://www.nature.com/articles/nature14236). This explanation is going to be brief, and so I strongly suggest looking at the original paper, as well as this excellent series of [blog posts](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0), and Chapter 3 of this [book](http://incompleteideas.net/book/bookdraft2018mar11.pdf).\n",
    "\n",
    "Ok, lets get started. To understand how this works, we have to introduce a few definitions:\n",
    "\n",
    "Firstly, we define an Agent's *policy* $\\pi$ as a mapping from states to probabilities of specific actions - i.e. $\\pi(a|s)$ is the probability that $A_t = a$ if $S_t = s$.\n",
    "\n",
    "Next, for FMDP's we define the *value* of a state $s$, under policy $\\pi$ as:\n",
    "\n",
    "$$v_{\\pi}(s) = \\mathbb{E}_{\\pi}[G_t|S_t = s]  = \\mathbb{E}_{\\pi} \\Big[\\sum_{k = 0}^{\\infty}\\gamma^k R_{t+k+1}\\Big| S_t = s \\Big] \\qquad \\forall S_t \\in \\mathcal{S} $$\n",
    "\n",
    "where $G_t$ is the discounted return (discounted cumulative reward) with discount factor $0 \\leq \\gamma \\leq 1$ and $v$ is the *state-value function*.\n",
    "\n",
    "Similarly, we can define the *action-value function*  (the so called \"q\" function) for policy $\\pi$ via:\n",
    "\n",
    "$$q_{\\pi}(s,a) = \\mathbb{E}_{\\pi}[G_t|S_t = s, A_t = a]  = \\mathbb{E}_{\\pi} \\Big[\\sum_{k = 0}^{\\infty}\\gamma^k R_{t+k+1}\\Big| S_t = s, A_t = a \\Big]$$\n",
    "\n",
    "Importantly, both state and action value functions satisfy a relation (actually system of equations) known as Bellman's equation, which for action-value functions looks as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "q_{\\pi}(s,a) & =  \\mathbb{E}_{\\pi}[G_t|S_t = s, A_t = a] \\\\\n",
    "& = \\mathbb{E}_{\\pi}[R_{t+1} + \\gamma G_{t+1}|S_t = s, A_t = a]\\\\\n",
    "& = \\sum_{s'}\\sum_{r}p(s',r|s,a)\\big[r + \\gamma\\mathbb{E}_{\\pi}[G_{t+1}|S_{t+1} = s']\\big] \\\\\n",
    "& = \\sum_{s'}\\sum_{r}p(s',r|s,a)\\big[r + \\gamma v_{\\pi}(s')\\big]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In addition, value functions allow us to place an order over policies ($\\pi > \\pi' \\iff v_{\\pi}(s) > v_{\\pi'}(s)\\quad \\forall s \\in \\mathcal{S} $) such that we can define an optimal policy $\\pi^*$, with respect to which the action-value function will be the unique solution of the following system of equations:\n",
    "\n",
    "$$q_*(s,a) = \\mathbb{E}\\big[R_{t+1} + \\gamma\\max_{a'}q_{*}(S_{t+1},a')\\big|S_t = s, A_t = a \\big]\\tag{1}$$\n",
    "\n",
    "Now, the idea of iterative Q-learning is to start from an arbitary $q$ function, and then use eqn. (1) as an update function for an agent which uses the $q$ function to make decisions as to how to interact with the environment. The hope (can be proven under certain constraints) is that the $q$ function will eventually converge to $q_*$, which is a stationary point of eqn. (1).\n",
    "\n",
    "More specifically, for *deep*-Q learning we parameterize $q$ with a neural network, and use eqn. (1) to construct the cost function on which we train the network. In particular we let the agent interact with the environment, using some $\\epsilon$-greedy policy, in the process generating tuples of experience of the following form:\n",
    "\n",
    "$$[S_t,A_t,R_{t+1},S_{t+1}]$$\n",
    "\n",
    "From these tuples we can construct a loss on which to train the Q-network, by using the cost function:\n",
    "\n",
    "$$\\begin{align} \n",
    "C &= y_{\\mathrm{pred}} - y_{\\mathrm{true}}\\\\\n",
    "&= q(S_t,A_t) - \\big[R_{t+1} + \\gamma\\max_{a'}q(S_{t+1},a') \\big]\n",
    "\\end{align}$$\n",
    "\n",
    "which, by staring at eqn. (1), we can see will be 0 only for the optimal policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b) Some practical considerations\n",
    "\n",
    "The idea of Q-learning has been around for a long time, however it is only [relatively recently](https://www.nature.com/articles/nature14236) that people started having success with deep-Q learning, as many aspects of the problem make the training process extremely unstable. In order to deal with this, the landmark deep-Q learning paper introduced the following tricks:\n",
    "\n",
    "  - _Memory buffer_: Rather than training online after each interaction with the environment, collect experience-tuples in a memory buffer from which you can randomly sample to create training batches\n",
    "  - _Seperate active and target network_: Because the q-function is used to create both the \"truth-label\" and the prediction of the cost function, training can be extremely unstable. To fix this one can create a target network, which is an exact copy of the q-network from which the agent is making decisions, but which is updated less frequently.\n",
    "  \n",
    "In addition to these tricks, there have since been subsequent additional ideas, which have helped a lot:\n",
    "\n",
    "  - [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952): Instead of sampling batches randomly from the memory buffer, sample according to a probability distribution which gives more weight to experience tuples from which the agent stands to learn more.\n",
    "  - [Double Q Learning](https://arxiv.org/abs/1509.06461): When using a seperate target and active q-network, the loss function can systematically over-estimate the  value of certain actions. Double Q learning modifies the loss function to address this problem.\n",
    "  - [Dualing Q Networks](https://arxiv.org/abs/1511.06581): See the paper :)\n",
    "\n",
    "It's also worth mentioning different methods and extensions of Q-learning, such as [Asynchronous Actor Critic](https://arxiv.org/abs/1602.01783), which has proven extremely powerful.\n",
    "\n",
    "\n",
    "Practically, the Q-function is parameterized via a NN which takes as input the current state $S_t$, and has as many outputs as there are legal actions, with each output corresponding to the state-action value for that action given the input state.\n",
    "\n",
    "Once again, as when discussing GAN's, the neural network architecture via which the q function is parameterized is of course up to you - for tasks in which the state $S_t$ is an image (like in the Atari environment) it would make sense to use a CNN, or perhaps an LSTM if one wants to see historical sequences of frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a) Lets build and train a Deep-Q network\n",
    "\n",
    "To give an example, we will use the [openAI gym](https://gym.openai.com/) [cart-pole environment](https://gym.openai.com/envs/CartPole-v0/).\n",
    "\n",
    "OpenAI gym provides multiple environments which can interface with any agent you build. You just need to supply a valid action, and the environment will respond with a new environment state and a reward. There are [lots of cool environments](https://gym.openai.com/envs/#classic_control) - including locomotion and Atari :)\n",
    "\n",
    "The cart pole task is to balance a pole on a cart:\n",
    "\n",
    "<img src=\"images/cart_pole.gif\",width=350,height=350>\n",
    "\n",
    "In particular, at anytime the state of the environment that the agent has access to is a four dimensional vector:\n",
    "\n",
    "     - [position of cart, velocity of cart, angle of pole from vertical, angular velocity of pole]\n",
    "\n",
    "and the agent only ever has two valid actions:\n",
    "\n",
    "     - [move_cart_left, move_cart_right]\n",
    "     \n",
    "The game is over when the pole hits the ground, and the agent recieves a reward of 1 for every time step in which the game is not over.\n",
    "\n",
    "We will build a completely vanilla implementation, with a simple FFNN, in essence a simplified version of the methods used in the original [Atari paper](https://www.nature.com/articles/nature14236)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Imports ---------------\n",
    "\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the Atari paper, training is more stable if the losses are clipped, which can be achieved by a custom loss function, the [Huber Loss](https://en.wikipedia.org/wiki/Huber_loss). This can be defined in Keras as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "    error = y_true - y_pred\n",
    "    cond  = K.abs(error) < clip_delta\n",
    "\n",
    "    squared_loss = 0.5 * K.square(error)\n",
    "    linear_loss  = clip_delta * (K.abs(error) - 0.5 * clip_delta)\n",
    "\n",
    "    return tf.where(cond, squared_loss, linear_loss)\n",
    "\n",
    "def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
    "    return K.mean(huber_loss(y_true, y_pred, clip_delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we will use our simple function for building FFNN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_FFNN(num_features, num_categories,ff_layers, learning_rate):\n",
    "\n",
    "    nnet = Sequential()\n",
    "    \n",
    "    for layer in range(len(ff_layers)):\n",
    "        \n",
    "        if layer == 0:\n",
    "            nnet.add(Dense(ff_layers[0][0], activation='relu', input_shape=(num_features,)))\n",
    "        else:\n",
    "            nnet.add(Dense(ff_layers[layer][0], activation='relu'))\n",
    "                \n",
    "        if ff_layers[layer][1] > 0:\n",
    "            nnet.add(Dropout(ff_layers[layer][1]))\n",
    "\n",
    "    nnet.add(Dense(num_categories,activation=\"linear\"))\n",
    "    \n",
    "    ad_opt = Adam(lr=learning_rate)\n",
    "    nnet.compile(optimizer=ad_opt, loss=\"mean_squared_error\")\n",
    "    \n",
    "    return nnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need helper functions for action selection and batch construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action(Q_nn,observation,epsilon):\n",
    "    \n",
    "    if np.random.rand() < epsilon:\n",
    "        # With probability epsilon act randomly\n",
    "        action = random.randrange(2)\n",
    "    else:\n",
    "        # With probability 1- epsilon act in a greedy way with respect to the active Q function\n",
    "        action = np.argmax(Q_nn.predict(np.expand_dims(observation,axis=0))[0])\n",
    "        \n",
    "    return action\n",
    "       \n",
    "def construct_training_batch(memory_buffer, batch_size, target_network, active_network, gamma):\n",
    "    \n",
    "    # Sample a random selection of experience-tuples/memories\n",
    "    mini_batch = random.sample(memory_buffer, batch_size)\n",
    "    \n",
    "    x_batch, y_batch = [], []\n",
    "    for state, action, reward, new_state, done in mini_batch:\n",
    "        # For each experience-tuple in the sampled batch of memories:\n",
    "        \n",
    "        # Get the current action values. \n",
    "        target = active_network.predict(np.expand_dims(state,axis=0))[0]\n",
    "        \n",
    "        if done:\n",
    "            # If in the terminal state, the expected future reward is just the current reward.\n",
    "            # We replace the action value for the action we took with this value for y_true\n",
    "            target[action] = reward\n",
    "        else:\n",
    "            # if not in the terminal state, then we bootstrap y_true using Bellmans equation for the optimal q function\n",
    "            target[action] = reward + gamma*np.max(target_network.predict(np.expand_dims(new_state,axis=0))[0])\n",
    "        \n",
    "        # Add this state and target function to the training batch\n",
    "        x_batch.append(state)\n",
    "        y_batch.append(target)\n",
    "        \n",
    "    return np.array(x_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then set up the environment and define all relevant settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ------------- Env Specification ----------\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# ---------- FFNN specification -------------------\n",
    "\n",
    "ff_layers = [[20,0],[20,0]]               # We use a very small FFNN\n",
    "learning_rate = 0.001\n",
    "num_outputs = 2                           # The number of outputs is the number of valid actions\n",
    "num_features = 4                          # The number of features is the given by the state description\n",
    "\n",
    "# ---------- Training specifications -------------\n",
    "\n",
    "min_buffer_size = 100                     # We only start training after collecting 100 memories\n",
    "max_buffer_size = 1000                    # The buffer is a queue with maximum length 1000\n",
    "batch_size = 32       \n",
    "max_episodes = 200\n",
    "max_episode_length = 1000\n",
    "\n",
    "\n",
    "# -------- Other agent specifications ----------\n",
    "\n",
    "gamma = 0.99                                   # Discounting factor\n",
    "epsilon_initial = 0.99                         # intial exploration probability\n",
    "epsilon_decay = 0.995                          # epsilon decay factor\n",
    "epsilon_min = 0.01                             # minimum exploration probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can train the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 201  Final Episode Length:  115\n",
      "Training Stopped\n"
     ]
    }
   ],
   "source": [
    "# ------------ Algorithm -----------------------------------\n",
    "\n",
    "# 1) Initialize the memory buffer\n",
    "memory_buffer = deque(maxlen=3000)\n",
    "\n",
    "# Initialize lists to store improvement metrics\n",
    "episode_lengths = []\n",
    "\n",
    "# 2) Initialize the Q network and the target Q network\n",
    "\n",
    "Q_nn = build_FFNN(num_features, num_outputs,ff_layers,learning_rate)\n",
    "Q_nn_target = build_FFNN(num_features, num_outputs,ff_layers,learning_rate)\n",
    "\n",
    "Q_nn_weights = Q_nn.get_weights()\n",
    "Q_nn_target.set_weights(Q_nn_weights)\n",
    "\n",
    "# 3) Initialize relevant variables and counters\n",
    "epsilon = epsilon_initial\n",
    "\n",
    "stop_training = False\n",
    "episode = 1\n",
    "while not stop_training:\n",
    "    \n",
    "    # Reset the environment and relevant flags and counters\n",
    "    observation = env.reset()      \n",
    "    stop_episode = False\n",
    "    episode_length = 1\n",
    "\n",
    "    while not stop_episode and not stop_training:\n",
    "            \n",
    "        # Choose an action in an epsilon greedy manner\n",
    "        action = epsilon_greedy_action(Q_nn,observation,epsilon)  \n",
    "        \n",
    "        # Act with this action\n",
    "        new_observation, reward, terminal_state, info = env.step(action)\n",
    "        \n",
    "        # Construct the experience-tuple and add it to the memory buffer\n",
    "        memory = [observation, action, reward, new_observation, terminal_state]\n",
    "        memory_buffer.append(memory)\n",
    "        \n",
    "        observation = new_observation\n",
    "        \n",
    "        # If we have enough memories we can train the neural network\n",
    "        if len(memory_buffer) > min_buffer_size:\n",
    "            \n",
    "            # Fetch the training batch and the targets\n",
    "            training_inputs, training_targets = construct_training_batch(memory_buffer, batch_size, Q_nn_target,\n",
    "                                                                        Q_nn, gamma)\n",
    "            \n",
    "            # Fit the neural network on this batch\n",
    "            Q_nn.fit(x=training_inputs, y = training_targets, batch_size=batch_size,verbose=0)\n",
    "                    \n",
    "        # lets anneal the exploration probability\n",
    "        if epsilon > epsilon_min:\n",
    "                epsilon = epsilon*epsilon_decay\n",
    "            \n",
    "        # check if the episode should end:                                                      \n",
    "        if terminal_state or episode_length > max_episode_length:\n",
    "            stop_episode = True\n",
    "            episode +=1\n",
    "            episode_lengths.append(episode_length)\n",
    "            \n",
    "            clear_output()\n",
    "            print(\"Episode:\", episode, \" Final Episode Length: \", episode_length)\n",
    "            \n",
    "            # Update the target neural network\n",
    "            Q_nn_target.set_weights(Q_nn.get_weights())\n",
    "            \n",
    "        # check if training should end\n",
    "        if stop_training or episode > max_episodes:\n",
    "            stop_training = True\n",
    "            print(\"Training Stopped\")\n",
    "            episode_lengths.append(episode_length)\n",
    "                                 \n",
    "        episode_length += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsnXd4VGX2xz+HJCT0DkIAKasovcliQREQy7rq7toQFdRVdy2r7s+CBcva+6prWV3rCgiK7qpbRLFghQWkCoJA6L2GEkh5f3+cuZmbyUwySaYlnM/zzHNn3rn3zpk7yfu955z3Pa845zAMwzCMUGol2wDDMAwjNTGBMAzDMMJiAmEYhmGExQTCMAzDCIsJhGEYhhEWEwjDMAwjLCYQhmEYRlhMIAzDMIywmEAYhmEYYUlPtgFVoXnz5q5Dhw7JNsMwDKNaMWvWrC3OuRbl7VetBaJDhw7MnDkz2WYYhmFUK0RkZTT7WYjJMAzDCIsJhGEYhhEWEwjDMAwjLNU6BxGO/Px81qxZQ15eXrJNMapIVlYWbdu2JSMjI9mmGMZBSY0TiDVr1tCgQQM6dOiAiCTbHKOSOOfYunUra9asoWPHjsk2xzAOSmpciCkvL49mzZqZOFRzRIRmzZqZJ2gYSaTGCQRg4lBDsN/RMJJLjRQIwzCMZOEcvPYa7N+fbEuqjglEEunQoQNbtmwBoH79+gCsW7eOs88+O5lmGYZRBebNg0sugY8/TrYlVccEIo445ygqKqrQMW3atOGdd96Jk0VVp6CgINkmGEZK43kO5kEYpcjJyaFLly5cfPHFdO/endWrVzNhwgR69OhB9+7dueWWW8o9vnv37gC89tpr/PrXv+aUU07hsMMO4+abby7e7+WXX+bwww9nwIABXH755VxzzTWlzjVjxgyOPvpo+vTpwzHHHMOPP/4IwMCBA1m4cGHxfoMHD2bmzJns2bOHSy+9lAEDBtCnTx/++c9/FttxxhlnMGTIEIYOHcru3bsZOnQoffv2pUePHsX7Adx777106dKF4447jhEjRvDYY48BsGzZMk455RT69evHoEGDWLx4cSWvsGGkNoWFuq0J91JxG+YqIq8ApwObnHPdA20TgS6BXRoDO5xzvUWkA7AI+DHw3nfOud9V2Yjrr4c5c6p8mhL07g1//nOZuyxdupTXX3+dgQMHsm7dOm655RZmzZpFkyZNGD58OP/4xz8466yzovq4OXPm8P3335OZmUmXLl249tprSUtL495772X27Nk0aNCAIUOG0KtXr1LHHnHEEXz55Zekp6fzySefcNtttzF58mTOO+88Jk2axD333MP69etZv349/fv357bbbmPIkCG88sor7NixgwEDBjBs2DAAZs+ezbx582jatCkFBQW89957NGzYkC1btjBw4EDOOOMMZs6cyeTJk5k7dy75+fn07duXfv36AXDFFVfwwgsvcNhhhzF9+nSuuuoqPv300wpefMNIfTxh8ISiOhPPeRCvAX8B3vAanHPnec9F5HFgp2//Zc653nG0J2EceuihDBw4EID//e9/DB48mBYttHDiyJEjmTZtWtQCMXToUBo1agRA165dWblyJVu2bOGEE06gadOmAJxzzjksWbKk1LE7d+5k1KhRLF26FBEhPz8fgHPPPZfhw4dzzz33MGnSpOKcx5QpU3j//feL7/rz8vJYtWoVACeddFLx5znnuO2225g2bRq1atVi7dq1bNy4ka+//pozzzyTrKwssrKy+OUvfwnA7t27+eabbzjnnHOKbdtfE/xvwwiDeRBR4JybFvAMSiE6fvFcYEi8Ph8o904/XtSrVy9m58rMzCx+npaWVqEcwNixYznxxBN57733yMnJYfDgwQBkZ2fTrFkz5s2bx8SJE3nhhRcA7fgnT55Mly5dSpxn+vTpJb7TuHHj2Lx5M7NmzSIjI4MOHTqUOV+hqKiIxo0bMyfW3pxhpCCeQNQEDyJZOYhBwEbn3FJfW0cR+V5EvhCRQUmyK+YMGDCAL774gi1btlBYWMiECRM44YQTqnTOo446ii+++ILt27dTUFDA5MmTw+63c+dOsrOzAc0j+DnvvPN45JFH2LlzJz179gTg5JNP5plnnsE5B8D3338f8bwtW7YkIyODzz77jJUrtXLwscceywcffEBeXh67d+/mww8/BKBhw4Z07NiRt99+G1Ahmjt3bpWugWGkKt49XE3wIJIlECOACb7X64H2zrk+wB+B8SLSMNyBInKFiMwUkZmbN29OgKlVo3Xr1jz00EOceOKJ9OrVi379+nHmmWdW6ZzZ2dncdtttDBgwgGOPPZYOHToUh6H83Hzzzdx666306dOnlOdx9tln89Zbb3HuuecWt40dO5b8/Hx69uxJt27dGDt2bNjPHzlyJDNnzqRHjx688cYbHHHEEYAK1xlnnEHPnj059dRT6dGjR7Fd48aN4+WXX6ZXr15069atRGLbMGoS8fAgvvoKVka1gkOMcc7F7QF0ABaEtKUDG4G2ZRz3OdC/vPP369fPhfLDDz+UaquJ5ObmOuecy8/Pd6effrp79913k2yR4tm1Z88e169fPzdr1qwqne9g+T2NmsP77zsHzj3zTOzOmZ3t3O9/H7vzATNdFH14Mor1DQMWO+fWeA0i0gLY5pwrFJFOwGHA8iTYVm24++67+eSTT8jLy2P48OFRJ73jzRVXXMEPP/xAXl4eo0aNom/fvsk2yTASSjw8iD17YPfu2J0vWuI5zHUCMBhoLiJrgLuccy8D51MyvARwPPAnEckHioDfOee2xcu2moA30ijVGD9+fLJNMIykEo8cxIEDkIy6lfEcxTQiQvvoMG2TgfCZVsMwjGpEPDyI/fuTMzPbZlIbhmHEkFjPgygs1EcyPAgTCMMwjBgS65nUgfmtJhCGYRjVnVh7EAcO6NZCTAcpd955J5988kmVz+OVDI8Wf7nxWJGTk1MiUf3aa6+FLSRoGDWVWOcgPIEwD+Ig5U9/+lNxUbzqTqhAGMbBRqxHMXmegwlEDeHNN99kwIAB9O7dmyuvvJLCwK1E/fr1ueGGG+jWrRtDhw7Fmwk+evTo4jUgxowZQ9euXenZsyc33ngjoJ3ukCFD6NmzJ0OHDi0uoLdixQqOPvpoevTowR133FHChkcffZSjjjqKnj17ctddd1XJ5ttvv51evXoxcOBANm7cCGj57oEDBxZ/tue9jBkzhi+//JLevXvz5JNPAroIUmjJ8sLCQkaPHk337t3p0aNH8b6GUd2JlwdhIaYYc/31MHhwbB/XX1/2Zy5atIiJEyfy9ddfM2fOHNLS0hg3bhwAe/bsoX///ixcuJATTjiBe+65p8SxW7du5b333mPhwoXMmzevuNO/9tprGTVqFPPmzWPkyJH84Q9/AOC6667j97//PfPnz6d169bF55kyZQpLly5lxowZzJkzh1mzZjFt2rRK2zxw4EDmzp3L8ccfz0svvVT82ddddx3z58+nbdu2xed66KGHGDRoEHPmzOGGG24AtGT5xIkTmT9/PhMnTmT16tXMmTOHtWvXsmDBAubPn88ll1xS9oU1jGpCvHIQ5kHUAKZOncqsWbM46qij6N27N1OnTmX5cp0UXqtWLc47TyueX3jhhXz11Vcljm3UqBFZWVlcdtllvPvuu9StWxeAb7/9lgsuuACAiy66qPi4r7/+mhEjRhS3e0yZMoUpU6bQp08f+vbty+LFi1m6dCmRKMvm2rVrc/rppwPQr18/cnJyim3yynd7tkXCK1melZVVXLK8U6dOLF++nGuvvZb//ve/NGwYtvSWYVQ7Yj2KKZkCkYxSGwkjGdW+nXOMGjWKBx98sNx9tep5kPT0dGbMmMHUqVN55513+Mtf/lLuojqh5/BsuPXWW7nyyiurbHNGRkbxZ1S03LhHuJLlTZo0Ye7cuXz00Ue88MILTJo0iVdeeaXC5zaMVMNGMRkRGTp0KO+88w6bNm0CYNu2bcXlsIuKiopzDePHj+e4444rcezu3bvZuXMnp512Gk8++WRxSexjjjmGt956C9CqqIMGaTX0Y489tkS7x8knn8wrr7zC7kDxlrVr1xbbU1GbIzFw4MDiMuOeDQANGjQgNze3zGMBtmzZQlFREb/5zW+47777mD17drnHGEZ1IJ6jmAKV+BNGjfYgkkHXrl257777GD58OEVFRWRkZPDss89y6KGHUq9ePWbMmMF9991Hy5YtmThxYoljc3NzOfPMM8nLy8M5xxNPPAHAM888wyWXXMKjjz5KixYtePXVVwF46qmnuOCCC3j44YdLlBAfPnw4ixYt4uijjwY00fzmm2/SsmXLCtsciT//+c9ceOGF3H///ZxyyinFZb179uxJWloavXr1YvTo0TRp0iTs8WvXruWSSy6hqKgIICqPyzCqA7H2IDzPwTmdNFe7dmzOGw3iEi1JMaR///5u5syZJdoWLVrEkUcemSSLyqZ+/frFd/XVnb1791KnTh1EhLfeeosJEybEZY2HVP49DSMc99wDd98No0ZByDpdlWLKFDj5ZH2+axc0aFD1c4rILOdc//L2Mw/CqBSzZs3immuuwTlH48aNLX9gGAHilYMADTPFQiCixQQigdQU7wFg0KBBtmyoYYQhXjkISPxIphqZpK7OYTMjiP2ORnUk1jOp/QKR6JFMNU4gsrKy2Lp1q3Uu1RznHFu3biUrKyvZphhGhYi1B+EXhUR7EDUuxNS2bVvWrFlTXMbCqL5kZWWVmKVtGNWBeOcgEkmNE4iMjAw6duyYbDMMwzhIiddMarAQk2EYRrWmJnkQJhCGYRgxxEYxRYGIvCIim0Rkga/tbhFZKyJzAo/TfO/dKiI/iciPInJyvOwyDMOIJ/GaSR36PBHE04N4DTglTPuTzrnegce/AUSkK3A+0C1wzHMikhZH2wzDMOJCPHMQNcaDcM5NA7ZFufuZwFvOuf3OuRXAT8CAeNlmGIYRLywHUTWuEZF5gRCUV8ktG1jt22dNoM0wDKNaEc8cRE0KMYXjeaAz0BtYDzxe0ROIyBUiMlNEZtpcB8MwUo14zKTOyNDnNdqDcM5tdM4VOueKgJcIhpHWAu18u7YNtIU7x4vOuf7Ouf4tWrSIr8GGYRgVJB4zqQPV9Gu2QIhIa9/LXwHeCKf3gfNFJFNEOgKHATMSaZthGEYsiEcOon59fZ7oEFPcZlKLyARgMNBcRNYAdwGDRaQ34IAc4EoA59xCEZkE/AAUAFc752Kkv4ZhGIkjHqOYMjP1UWNKbTjnRoRpfrmM/e8H7o+XPYZhGIkgHh5E7dqQlVXDQ0yGYRg1nXiMYqpdWz2Imj6KyTAMo0YTj1FMmZnmQRiGYVR74jGKyUJMhmEYNYB45SAsxGQYhlHNiVcOwjwIwzCMak48chAmEIZhGDWAeHgQ3jwICzEZhmFUY+KxHoR5EIZhGDWAeMykNoEwDMOoAdgoJsMwksLrr8NTTyXbCqMs/J5DUVHVz2cehGEYUTFhArz6arKtMMrC7znEwotIpkDErVifYRixJz8/8Z2EUTH8HkRV8xDOBUcx5edbiMkwjDLIz4d9+5JthVEWflGoqgeRn69b8yAMwygXE4jUJ5YehLcede3aeq6CAt2mpVXtvNFiHoRhVCNMIFKfWOYg/AKRlaXPExlmMoEwjGqE5SBSn8JCyMgIPq8K4QQikb+/CYRhVCPy8/WuNFZj7I3YU1ioHTpU/XfyvAWv1AaYQBiGEQEvaWlhptSloCDYmcfDg7AQk2EYYfEEwsJMqUthYVAg4pGDqBEehIi8IiKbRGSBr+1REVksIvNE5D0RaRxo7yAi+0RkTuDxQrzsMozqjHkQiWPPHvjXvyp+nF8gYulB1LQQ02vAKSFtHwPdnXM9gSXArb73ljnnegcev4ujXYZRbTGBSByTJsHpp8OGDdEf41xscxDJDjFFNQ9CRLKBQ/37O+emlXWMc26aiHQIaZvie/kdcHa0hhqGYSGmRLJnT8ltNHi1l2LtQWRmBuc+JPK3L1cgRORh4DzgB8D7ug4oUyCi4FJgou91RxH5HtgF3OGc+7KK5zeMGod5EInD65wrcsfuCUKschDeZ9euDemB3jqlBAI4C+jinIuZYyMitwMFwLhA03qgvXNuq4j0A/4hIt2cc7vCHHsFcAVA+/btY2WSYVQLTCASh3etPaGIBk8Q4pGD8MJWqTaKaTmQEasPFJHRwOnASOecA3DO7XfObQ08nwUsAw4Pd7xz7kXnXH/nXP8WLVrEyizDqBaYQCQO71on04NI9iimiB6EiDyDhpL2AnNEZCpQfKmcc3+o6IeJyCnAzcAJzrm9vvYWwDbnXKGIdAIOQ4XJMIwAhYWaBAXLQSQCr3OuiAcRKhDVfRRTWSGmmYHtLOD9kPdceScWkQnAYKC5iKwB7kJHLWUCH4sIwHeBEUvHA38SkXygCPidc25bBb6HYdR4vDtaMA8iEVTFg4j1KKbMzBQbxeScex1ARK5zzpVYw0pErivvxM65EWGaX46w72RgcnnnNIyDGROIxFKZJHWschAzZkCnTiWT1Kk6UW5UmLbRMbbDMIxy8AuEhZjiT2WS1LHKQQwfDo88ksIhJhEZAVyADj/1h5gaABb+MYwEYx5EYolFkroyHkRREezcCatXQ3a2tvkFIiVCTMA36PDT5sDjvvZcYF48jTIMozQmEImlKiGmquQgvN9248aSHkR6uj5SwoNwzq0EVgJHJ84cwzAiYQKRWGIRYqqMB7E3ML5zw4aSSWpvmxIC4SEiuZQetbQTHeX0f845G45qGAnAchCJJVkzqb3SHhs2BD/bm0WdlZV6E+X+DNwEZANtgRuB8cBbwCvxM80wDD/mQSSWyuQgQkNMVfEgtm+H3Fw9l84KUIH4z3/g/PPhqacinyNWRCMQZzjn/uqcy3XO7XLOvQic7JybCDSJs32GYQQwgUgsyRrFtHdv8PmaNUGxAfjVr3Q50zlzYOXKip+7okRTi2mviJwLvBN4fTbgObjlTpgzDCM2WIgpscQixFQVDwJg1aqSAvHMMxU/X1WIxoMYCVwEbAI2Bp5fKCJ1gGviaJthGD7Mg0gsyarFFCoQ3rmSQbkeRCAJ/csIb38VW3MMw4iECURiqUwtpljMpPYLxIYNcOihFT9HrIhmFFML4HKgAyUXDLo0fmYZhhGKJxC1a1uIKRGkggcBJUNMiSaaHMQ/gS+BTwguGGQYRoLxOqyGDc2DSARVSVLHYhSTR6oLRF3n3C1xt8QwjDIxgUgssSjWVxUPonVrWL8+uQIRTZL6QxE5Le6WGIZRJl6H1aCBCUQiSFYtJk8gOnXSbaoLxHWoSOSJyC4RyRWRUkuBGoYRX/wehOUg4k8y50GkpUG7diXPlQyiGcXUIBGGGIZRNhZiSiyxKNZXWQ+ibl045JCS50oG5XoQolwoImMDr9uJyID4m2YYhp9oBKKgoHSS06gcyRzFVG0EAngOreh6QeD1buDZuFlkGEZYvA6rQQPttFyYOgb33QcDBybWrppKstakrm4C8XPn3NUEyms457YDSTTZMA5O/B4EhM9DrFoFOTkJM6lGUxUPIi0NatU6ODyIfBFJI1B3KTBxriiuVhmGUYpQgQgXZtq/XzuYcN6FUTGqUs3VW9wnFh5EMpPU0QjE08B7QEsRuR8tr/FANCcXkVdEZJOILPC1NRWRj0VkaWDbJNAuIvK0iPwkIvNEpG8lvo9h1Fj8ISYI70Hs36+dkr8sh1E5qhJiSkvTR2U9iHr1qokH4ZwbB9wMPIguQXqWc+7tKM//GnBKSNsYYKpz7jBgauA1wKnAYYHHFcDzUX6GYRwUROtBRHrPiJ7CwqAXVtkQU1U9iObNNUyVkgIRuNNvKiJN0UquE9CFgjYG2srFOTcN2BbSfCbweuD568BZvvY3nPId0FhEWkf/VQyjZhPqQZQlEDaSqWr4vYbKFOtLT6+aB1G3rh7/61/DMcdU/Byxoqx5ELPQvENgLaPitR8k8LxTJT+zlXNufeD5BqBV4Hk2sNq335pA23pfGyJyBeph0L59+0qaYBjVj/x87Xjq1NHXJhDxwx+iS5YHAfB2tLGaOBFRIJxzHeP94c45JyIVSqcFVrR7EaB///6WijNqBP6OJRL5+bqaWFaWvg6Xg/Dudk0gqoYnELVqVV4gqupBpALRJKljzUYvdBTYbgq0rwXa+fZrG2gzjBrPsGFwSzklMT2BMA8i/nhCW79+5UJMsfIgkk0yBOJ9YFTg+Si0nLjXfnFgNNNAYKcvFGUYNZply2DevLL3MYFIHJ4HUb9+5EmJ4fAEobI5COdgz56DRCBEZALwLdBFRNaIyGXAQ8BJIrIUGBZ4DfBvYDnwE/AScFU8bTOMVCIvDzZvLnufaEJMiRrFtHMnnHGGlqOuifgFwrnoO/rQHERFBeLAASgqSh2BiGY9CETkOOAw59yrgYly9Z1zK8o7zjk3IsJbQ8Ps64Cro7HHMGoa+/bBpk1l75NKHsSCBfDBB3DZZXDmmfH9rGTgDzF5rzMyyj/OH2JKS6t4iMn73VJFIKIp1ncXcAtwa6ApA3gznkYZxsGG50GUFcpIJYHwPqemlh33exAQfaLaH2KqjAdR7QQC+BVwBrAHwDm3DrAS4IYRIwoK9JGfr6GbSKTSKKaaLhChHkRFBeKg8SCAA4Hwj1eLqV58TTKMgwt/J1tWHiIVPYiaOmM71IOIdiRTVXMQ1VEgJonIX9GZzZcDn6BJZMMwYoBfIMrKQ3gCUbs2iJTunJ2zEFOsqGyIqaBA506I1AwPIpoV5R4TkZOAXUAX4E7n3Mdxt8wwDhL8HX00HoSIhplCBaKgIJjDiPedfU33ICoSYlq6FPr0ge+/V0HwJjvWBA8iqlFMAUEwUTCMOFBRDwI0zBR69+7vxMyDqBoVCTH9+KPOXVi2rKRA1GgPQkRyCdZfKoVzrmFcLDKMg4yK5iBABSL07j2RAuHZXFMFoiIexK5dut23Tz2G9ECvWqM9COdcAwARuRctmPd3tFDfSMCqrBpGjPB39OV5EN4IpnAC4b/LtSR11aiIB5Gbq9u9e0t7EBVdlyPVBCKaJPUZzrnnnHO5zrldzrnn0dLchmHEgMp4EFlZFmKKJxVJUkcSiJrgQUQjEHtEZKSIpIlILREZSWBOhGEYVcfrZGvVqlgOIpkhppouEJ7H4K29UZEQU03KQUQjEBcA5wIb0cqr5wTaDMOIAV5Hn50duxyEjWKqGp4HUS8w66siIaZY5CC8uS7JJpphrjlYSMkw4oZ3F96uHSxfHnm/0BBT6Kxr8yBiR2VCTPv2xWYUU1aWepOpQDS1mNqKyHsisinwmCwibRNhnGEcDHh34e3bw5YtWs0zHKEeRKgIeJ1YgwYmEFWlIqOYYp2DSJXwEkQXYnoVXauhTeDxQaDNMIwY4HWy7dtrh7JjR/j9/AJRv35pEfA6tSZNbBRTZfjyS61MW1hYsVFMXg5i796Sw1wr60FUN4Fo4Zx71TlXEHi8BrSIs12GcdDgFwiInIcIFQjvztXD67QTKRA1yYP49FN4/30V6IokqSOFmA4WD2KriFwYGMWUJiIXAlvjbZhhHCz4Q0wQeSRTqEDs3l3yfa8Ta9zYPIiyWLQI3nijdLvnCezeXTpJXZkQ08HiQVyKjmLaEHicDVwST6MM42DCuwtvG8jsleVB1K6tz70Qk78D8gtEokYxVUcP4okn4JJLStvuJf337NFrnZYWnJgYTYgpVjOpq5VAOOdWOufOcM61CDzOcs6tSoRxhlFTyMmJfFeflweZmdCqlb6O1oOAkuf0h5i89SXiRXUWiB9+0IEAS5aUbPc6+j17givIpadrcUTzICIgIo+ISEMRyRCRqSKyORBmMgwjCpyD/v3h8cfDv79vn45Kat5cX0eTg/Bi4/4wk18gIL5hpuoaYnJOQ0ygQuEn1IPwKudmZtooprIY7pzbBZwO5AA/A26q7AeKSBcRmeN77BKR60XkbhFZ62s/rbKfYRipRF4ebN0KqyL43Xl5GsqoXVvDQ+E8iMJC7dxCPQh/ojoZAlHdPIhNm2D7dn3uCYWHPwdx4EAwnFe7duQQ0/79wfdCQ0yV8SD27EktgYim3Le3zy+At51zO0Wk0h/onPsR6A0gImnAWuA9NK/xpHPusUqf3DBSEO/O1OuYQvEEAqBFi/AehBcuChUIvwfhH+YKiRMI5/ROuzrgF4VQgQjnQUDZHoRfoA9WD+JDEVkM9AOmikgLIFb3DUOBZc65lTE6n2GkHN68hkgC4YWYQDv3cPMgohEIf5IaEiMQzkW/HGcq4IlCnz6RPQhPIDwPIjMz8nf0BKJWrdjNpK5WAuGcGwMcA/R3zuWjhfpiVXrjfGCC7/U1IjJPRF4RkSYx+gzDSCrenem2beHf93sQDRsGOyo/oQJRVg7CE4h45gf8d9TVKcy0aJFeu6FDNUntv8P3ficvxORd69q1y/cgWrQITpSrqgfhDa1NBSIKhIgMCWx/DQwGzgw8PwUVjCohIrWBM4C3A03PA53R8NN6IGxKT0SuEJGZIjJzc1mVzQwjRSjPg6iMQETyINLTw49wijWJLAwYSxYtgiOOgK5dVQRWrND2wsLgtaxIiMn7rVq2DHoQlc1BbNmin9OyZcW/V7woy4M4IbD9ZZjH6TH47FOB2c65jQDOuY3OuULnXBHwEjAg3EHOuRedc/2dc/1btLAJ3UbqU54H4Q8xVVQgQpPUmZnBEEU8BSIvL2hzdfIgfvgBjjxSHxAMM/mvozfMNZoktXfcIYdEl4P4/PPI12v+fN326FGhrxRXylpR7q7ANl6T4kbgCy+JSGvn3PrAy18BC+L0uYaRUDwPIje35CgXj7w8aNRInzdqVDUPIlECsX9/cEJedRGInTth3brSAnHGGSUr41YmSd2qleZj9uwJDlf2hKKoSHMUa9fCiSfC00/DtdeWPte8ebpNJYGIZh5EMxF5WkRmi8gsEXlKRJpV5UNFpB5wEvCur/kREZkvIvOAE4EbqvIZhpEq+JPO4RLQ4TwIF7IafLSjmDIzg+eKt0B4olZdQkyLF+v2yCPV9tatgx6EX5S9Uhv+JHU0ISZQwfDPpIagF+ENc/7f/8II9sXGAAAgAElEQVSfa/58zWV4EyZTgWiGub4FTAN+E3g9EpgIDKvshzrn9gDNQtouquz5DCOV8d+dbtsWvMP0CM1BeHeinghAMMThT5zWrp0cD6KoSDtQLxleXTwITww87+HII4NtoR5EaJI6kgj6PQjQ38M/igmCeYj1gfjI7NnhzzV/vnoPqTRkOJphrq2dc/c651YEHvcBKaRxhpHa+L2GcInqUIGA0osBhXoQULpgX6hAxOvO3hMrz4OoLgKxeLFev06d9LUnEM6V9CAqE2LyexD+HAQEPYh163S7aFFp8S4qgoULUyu8BNEJxBQROT+wHnUtETkX+CjehhlGTSHUgwglNMQEpfMQkQQiGUlqr7OsbiGmTZv0Tt/ruDt00Ou3a1fwN2rWLPw8iLIEok6d4O+Wn19yFBOU9iCKioL5Bo8VK/Rzq6NAXA6MBw4A+9GQ05UikisiYdJphmH42bEjOLY9Wg8iWoEI9SBq1w4WmYu3QFS3ENP27UGbQXMQoB23d73btAk/DyLSKKZdu3RehX8N6UgexPr1KjZQOsyUiglqiG6iXAPnXC3nXLpzLiPwvEHg0TARRhpGdWbnTr1bhdIC4VzlBaJBg/AhJgi/JGmsqK4exI4dkQXC8yBat654iKlhw5Kzn8vKQXTrpjmoWbNKnmf+fM09dOtW+e8XD6IZxSSBBYPGBl63E5GwcxQMwyjNjh3QsaM+Dw0xHTigIlHZEFO4UUygHVaiBKK6eBA7dgTrVEFpgUhL01FEofMgyiu1EepBRBrFtH69eih9+5b2IObPh86dU2sWNUQXYnoOOBq4IPB6N/Bs3CwyjBrGjh3a8dSvX9qD8DrXyoaYwuUgICgQBQWRJ+hVluoaYirLg9i1SwXPE12/BxGu1MbGjbr1QkzRehCtW0O/frBgQclzeiOYUo1oBOLnzrmrCRToc85tB2rH1SrDqEHs3KmdT5MmpTtrr3P17kC9u/LK5iD8ArFvH/zpT7EPW9SUEFOjRnrd163T36hhQ72DLy9JPXWqegI//FB2iMnvQRQUaJXe1q3VgygoUJEA/Q2XLoWePeP33StLNAKRHyjL7QAC1VyL4mqVYdQQCgu1E2ncWAUi1IPwOlfPg/CK8EUzzLWsHITnQUyaBBs2xPYuP9kexMUXwzXXVOyYoiK9pn6BENEOO9SD2LtXv6M/B+EPMX3zjZ7v88/Dh5jCeRAbN2oo0RMIgBkzdPvVV3q+446rwBfat08PijPRCMTT6HoNLUXkfuAr4IG4WmUYNQTPE2jUCJo2LT/ElJ6unXssPIgFC+DHH/V1qOBUBU8g6tXTTjDRAvH556WTvOWRm6sdtF8gICgQfg8C9LU/xJSfH+yPvRFH334bPsQULgfhDXFt3VrzUe3bw0cfBb9PRgYcE20J1NxcOPlkuPrqaL9+pYlmFNM44GbgQbTK6lnOubfLPsowDAhOkvM8iPJCTBC+YF8kgfAKxEFwmKt3vtWrg/tWViA2bYJLLglfVjwzU4UtkSGmAwe0plGkyriR8P8OfkI9CE8gCgpKhpi8z4ZgUb3vvguGmMrzIPwCIQKnnw4ff6y//2efwc9/HuU6ENu3w0knqTqdeGLU37+yRONB4Jxb7Jx71jn3F+fcovKPMAwDgh2zl4MoL8QEFRMI0Jg5lB7F5CdcDahomDYNXnstGA6B0gKRSA9i9Wq9k6+sQDQJWWXG70F4ISYPvwcBen337dN8QePG8NNP+rpBA903VBgieRAAv/iFivsHH6g3FFVfn58Pp54K338P77wD555boWtQGaISCMMwKof/zrVp06AH8dVXWrwtNMQEFRcI7+4+NMQEemcKlfcgPDvWrg22+QWiTp3ECkROjm537Chd0LAsPEEJ50Hs2qV5Gn+ICUp7EPv3a5mMoiK4yFc5rkED9Qq8ax5uJrVXZuOQQ3R74ol67caO1fcHD47iSzzwAEyfDm++CWfGas22sjGBMIw4EhpiysvTDunkk+Hee4MeRGVCTKGryoUTiJEjS9pRUTw7vA7O+xxQUUt0iMkTCO9uviy2bw+G2coKMYF6Yf4QE5RMUoN+by//MHp0UAi838H7DSN5EC1aBM9Zp46uavfjjypERx9d9ndh1iy47z5VpnPOKWfn2GECYRhxJDTEBJqc3LsXVq6MnQdRVKQdkdeZZWdr3aFf/EJfV1YgPPtTxYPwVoCD8sNMt94Kw4fr8/IEAkp7EN619obzLl+u+YesLB2S2qtX8DgIinKkHIT/syD42wwcWPIGoRTffKOi0LIlPPVUGTvGHhMIw4gjoSEmgHcDq6CsWVP1JDWoQPg7bYAxY3ScvrfoYlVDTH4PwrM5GUlqz4OA8gVi1SrNExQVRScQoTkIL8R02ml63F/+ogLRtat6BwMH6vuhHkSkUUzhBKJWLRgWaeEE5+CWW3T8a1ERTJ5cOokSZ0wgDCOOeB1zw4bB/+1//Uu3a9aET1I3ahR9uW/QkTSeQPiXyWzaVPepVavqIaZIHkSik9Q5OcE78/K+05Yt2jlv2RLct2FI9bg2bYLPI3kQ9evD5Zdr/zx9enDGszcs1ROdinoQ7drpSKg//jHCFxg7Fh55BH77W1UmT5ESiAmEYcSRHTu0g0lPDwqEVyI6NzdYsiFciMmfhPUEwr9cqT8HEepBeIiEF5xoKSsHkawktbfgT3kexJYtul27Vn+Hhg2DnbZHs2YlQ0nhBAJ0iVARvR6eQJx9Nvztb8GBAKEC4f1WBw7o7xwqEABHHRWm/pJz8MwzcP/9qkx//Wvwx04wJhCGEUe84ZMQDDEB/OpXuv3pJ92GhpiKikoW2/PWGfCvNuYPMXlj9EMFAvQONxZJam+imN9bSWSIaf9+taNPH31dnkBs3apbTyDCRWdEgiOLGjYMH2ICvdv3csOeQNSuDZddph4alE5Se9v169WTCScQpVi4EE45Bf7wB50s8dxzSV1izgTCMOKIv/6P10HVqgUjRujzpUt1G+pBQMk8hL94nEdZOQg/sfAgvFpCECxDUatWYj2IVav05joagThwoKS4hdZh8uN13GV5EAB33glnnRV5xnPoMFdv+/RDOlHlmB65YY4KsHWr1g/p1UsnnTz5pCar/C5jEkjupxtGDcffMTVqpDeDffoE70KXLtWO1t8P+AXC67zCCYTXmZUnEFX1INLTVSDWrdORUf7htInMQXgJ6t69dVvWd/K8Bwh6ENEIREaGPvzF+jyOPBLeey/yZ5bKQSxeCHTj+x/rcRFv0O+c/9O8QuPG+sN79TtmzdKRSvn58Lvfwd13l164PEkkTSBEJAfIBQqBAudcfxFpCkwEOgA5wLmB6rGGUS3ZuTO4oH1aGhxxhIaXvJILGzdqR++PIkTrQdSurQ9/kjqSB7F8eeXtP+wwnSC2dq2KW6hAJCrE5AlE5856jcryILz8A6iwbd8eXJMjFE8gvOvulWUvvt6bNsGcOTp8KTtbv/CSJfDJJ/Dll3pxt22jTtN3gZ+rQOzfT/o9Y4F3qZ9VwMOvd4Tnu8N11+k5a9XSDygq0nK7V16p+YYUWzEo2R7Eic4530/JGGCqc+4hERkTeH1LckwzjKqzYwd06RJ87ZV4rlVLhWPDhpLhJYheICBY0bU8D6IqIab+/VUgvER16Mp1sfYgvOU+Q0PvK1aoN5Odrd+pLIGIyoNYuBDmzaNLrX40rN+ZhmuXwKKt1CvswXYakfHYg/Dkf4PlViFYD9yjSxdV/c6dqfvPGcDPSZ80DhZ+S+NlMwG46950Wp87CM75VL2F+vVV5cL9oClGsgUilDOBwYHnrwOfYwJhVGP8SWoIJjQB2rZVgQidJOUJhL9TjyQQXkXX0GGufho1qlyIyTkViMMP187aG+oaTw9izx4Nw599Njz0UMn3cnK0CmpaWvi6Vn48D6JDhxCB2LsXXn0VXnyxeFr0VWRwDi3I6KUKWI9FQCNqr/oJWuyG22+HQYN02vPSparsHTvC8cerWgWoc8V2eAnSvvwcPv8b7S++mJ/uhE6dAjuIqNpWI5IpEA6YIiIO+Ktz7kWglXMuUNaKDUCrpFlnGFXEOe2Y/ALhp107mDmztAcRbtGg8gSivFFMubl6E1yrAsNS9uzR79CsmfaJkQQiP1/H+qel6ecMGgQvvFC5YfsPPgjLlsGnn5Z+LycnuLZ3kyZliN7GjWyZvhvoTM8W6/lyYRN27c2i8SfvwLjfq3r07w9PPw2DB1N761ayvUkTdetS/86fwVzIeOPl4O0qaBXVMqibraMQ0h55CNJ7wOjRdG5Y5iEpTzIF4jjn3FoRaQl8LCKL/W8651xAPEogIlcAVwC0b98+MZYaRiXYtUv7nEj5xrZtdVuVEFOoBxFJIDxvIFKiNpL9nj1t2kQOMXltdevqTfbcuRqer6hALFsGjz6qXtC8eaW/c06OFjMFFQhvBBh798LXX8OUKfqYN4+t3AbcT8///Y33GavHbFgExw+C669XFYswfLTe47oN542VRfEoplbNYOQfKnZwipK0Ya7OubWB7SZ0QaIBwEYRaQ0Q2G4Kc9yLzrn+zrn+Lbw6AoaRgmwK/PW2bBn+fU8gQkNM3pyoaHMQ0SSpoeJ5CP9iR9nZkT0ICIaZvH2WLKnYZwHceKN+xwceCFZO9di3T+cTeInmxhm72Z6zQ4siNWigRZeeekrdnQcfZMtZl1O/TgEdxwbLrjZ+fKwOHT3++DLnFnijwyqaIgidB1ETSIpAiEg9EWngPQeGAwuA94FRgd1GAf9Mhn2GUVHGjy+9GJA3byDSfUy7droN9SC8CWix9CCg4nkIvweRnV22B+ElqisrEAcOwIcf6mCe00/XttmzUddn0yZWfa7DsDqs+gJ+/WuavP0S23dnqGtz++3w73/z/ec7mXb3pzBmDFvqd6B5q3TaHNOh+DOi9Z4qKxChw1xrAskKMbUC3hNV8XRgvHPuvyLyP2CSiFwGrATivyKGYVSRnBwtq/3oo3oX7BGtBxEqEFC6YF8kgWjRQhf18RfQC8XzIKoiEG3aaOh+/359eJ2oZ7v3+Z6IFId/omTxYg3HHXUUHFZvHfUzmzPrjg8Zfd0lsGsXOQwHPqLDS7dDdg5Njr6cvd/U48D7/y0OBV3eX7/jTz/pKKbmzUvkkKMWCG8CYkVDTKHF+moCSfkqzrnlQK8w7VuBoYm3yDAqj1cuw9t6lOdBRAoxQWmBWL26ZGfnMWAAvPSSjtiEsj2IioaY/IUGvc9ev14FwisbEinEtG2bdtLNmkXxQfv2Me/tVUAXejxyEbVGvEkfvmD2to5wyYVw+OHkzD8aXoaOH/0VTupKk+cEvlFBaNlS7Zo1SyNH+/apmDVrVjmBMA8iSA3SOsNIDsuWldx6eB5EJIHwKomG8yCaNQueb/58Ld191VWl9/MSwV98odtwd72xCjGBClVZISZ/Ub8lPxRwdO1ZWgJ1/369tV6zRr+YiPbEP/4Ic+Ywv+A+MriBwwt+gHvvpe+S7rw0uSmFTz9LWhqsGKMdduth3UCC32n7dhWIf/9bXzun4a0tW3R4bpMmauv+/RUXiMomqU0gDMMoxpulHCoQmzdr/jScAIB2XNnZpUtQA5x3npaBnjlTy0ynpYVfSKxrVz1+zpzgOUOJNkm9fLkuP/DZZxry8QuElxxesaKcJPXqIroeuo8fVtZj6fCrOTrvRQDySecwlvJQxp2c32VZsDRqx45w003MnzKaI/cJGfNmAdD3Ddj7d+3sjzxSw3iHHhocpuvVtfLmQvzrX9qhHzigyW0vxCSi13j58oqHmCrqQXjXuczFf6oZVqzPMKqIJwyrVgXLcoN6EJHyDx7vvgt33FG6/bLLVFyeeAImTNAh+OHOVauWhpm8ib6VzUHMnKkd8eTJ2rkuWBAUiAYNdP5BrVr6XcN6EE+/CN27s27RDo5b+SZpFLDk8NNh0iRYu5YNi3awkg58c+Xr6hLNm6e9/mefwQMPMH9jK3r2DfbIffvqdpbqBTk5JUtl+AVi/374+GO44AK1ce5ctd0Lb2Vna3u0FbMrm4M46ij9PU84oWLHpTImEIZRRTyBKCxUkfDYvLl8gRgwQO+MQ2nYUEViwgRdmtRbWzoc3nrGoUX/PDIyNPxRlkBMm6Z33//5j77OydFOtk4dPb52bR11tWyZhpMyM4GiIrL+qktg7nvvv+xreSjbacqhIwfRqXMtlnT5pbo9bdqwaY/GbXJWlh5eun27Rp68Aoag1Svq1CkpEN4kOQgKxI4davvu3fCb3+is5a+/1ve8+Sdt2qhIRjtJ8PzzdfW4itbLE9E6WzUpxGQCYRhVwDntNL31if1hpk2bIucfouEPfwiW1D7zzMj7eXmIcN6DR3n1mLZsUXEZPFg7Ok8g/OGvTp0CHkReEZnrVsC559Lm71oPY8V941j3ki6Vl31SVw7rUqvESCZvYST/kqEe8+fr1i8Q6em6EM/UqToPbuPG8AKxfbuGl7KyYMgQ9YJmzND3vA7+0kvh5psjf/dQWreGq6+Ofv+ajAmEYVSBLVt0oppXhSFUIMrzIMqiY0e44QbNRZQVHvFWNCtLIMqrx7R5s3aomZk6umrFChWI4jIhu3bRee98ls3cxv7cA2R9MAnee4/Wj/yRQw5xzF5Up3gEU3a2JoiXLAmuiucl7FesKLlSHoQXCNA1m+fP14KpUFIgvHzC+vUwbpyusVO3rgqENyfECzENH65rdBsVxwTCMKqAl6A+7jjtXD2BKCpS8ajqZP/HHoP77it7n2bNtEOuqgfh3XF36AA5Kxw71+2moeSqEZ060Xn6ODYXNGU/WWReMlIPuukm+vYVZs8OjmBq00bt2bs32OZ5ELt3l55QOH++egShw3h/8QvdPvusbv05CG+505dfVjO8KtrecqSQMksqVGtMIAyjCniC8LOfaQjGE4wdO3TiV1U8iIpw0knBYbPhKG/RoM2boUXjfPjrX+mw7BNyvlrNrmlzaPjjDLjpJujbl04PXF68f2bntsVxnr59dRiuNw/E8yAgOKPaEwgoHWaaP1+9h9DqF0ccodf0ww/1td+DAP349es1vOclhk0gYosJhGFUAU8gOnXSEv/e6/ImycWaxx+Hzz+P/H6jho6dG/fpjr/9LYwapdnYYcOgd2+2TP+J5l//A373OzrkLWYNbdnaujsNj+2hvf+UKXQe3rn4fH5vpV8/9Zj+8x8N8zRsqIsMQXBG9aZNQQHwC0Reno466tmztM0i6kU4p5/XKqS2s5eHuOGG4LmPOCL4flST9IwyMYEwjCqwbJneudepExSIQPkgIHEeRGZm+PkUAHz0EY0/fpsdq3O1Fsi//qUz62bP1jhQ+/ZsTjuEFv3aw+zZdHz0aopcLX7a3JiGnVsW35Z37lzy8zy8Ianffqvegzf3ICMjKAYbNwYXTlqxInjsv/+tZcV/+cvwpnt1mbxhtn68MuTnnx9sa9RIf4/69csOuRnRYRPlDKMKLF8e7Dg7ddLObtOmxHsQYZkzR4fvfPwxjRo9z460ZrhV65A2rUvsVlAA22tD89N+Dn2gw45gu190GjfWEhvbtpXsfNu1085669ZgmCstTRf38cRg0yYNO23YUNKDGD9eO/khQ8J/hRNO0JnN4YYCP/64Di0OFYIjjyxd9sSoHOZBGDWW77/XEUCho2ZiybJlQYHwtsuXJ96DKMW99+qt/axZ8OSTNB/zW/IL08it37rUrtu26TXyxMwf6w/1SrzV0fydsoiGmaBkorlDh5IehLcQm9e2c6fmF847L3KBu8xMXXzoljDrSvbvHxzB5eeOO3ThIaPqmEAYNZYbb4Qnnyy5gH1Z5OZqRVb/bOiy2LdPR+mECsSyZUEPIimJ0scfhzvv1KnFy5bB9dfTso32wP5ksYd3fTyBaNcuONkrVCC87xh61+6FmfyJck8gCguDkwY7dAh6Fe++q0NSL7ig7K9z4YWRPYxwDB4MI0ZEv78RGRMIo0Yyd25w2cpNpZadCs9LL2lEZurU6Pb3EtJep9mxo4ZDvvhCP7Nx44qXa6g0zmlO4dprVRnPPRdef714woCX4A13LULFLD09WGm2ogLh9yA6dtSQ0tq1msRu1SooGs5peKlzZ51NbqQmJhBGjeTPfw4+D3fXHI5x43TrTdwqD2+EjjekMzNTSy1MnqylIxISXtqwAe6/X6v29esHf/0rjB4Nf/97iZoPnkBE40FAMMwUup52uBATwLHHamLYEwr/ObyZzZ5A7N2rI56mToWLLipzcTcjyZhAGDWODRv07tQLS0QjEIsXB1YwI3qB8Mb4e0M6QcMl27drBxj3BPWXX+okgDvu0A974QX98q++Wsp18cQqGg8CgpPSQj2I3r11e8ghJdvbtNGZ18cfH2wLFYiWLYPnveQSFYwbbij/axrJw0YxGTWOv/1NC8/df78WsosmxDRhgg6j7NlTC41Gw9Kl2sn5O9Fhw7SvjqZQX5V4803tZTt10lvx7t3L3N0Tq7I8CL9AeJ17qED066fFA9u3L32eUE/AO8f06bpt1So4N2HTJo2ARRyaa6QE5kEYNQrntO8cPFhj2+np5XsQzml4acgQ7eAXLYouUb1kSTC85JGRoeF/iKMHsWCBTnY77jjtfcsRB8+uZs3CX4vNm7Wj9jsd3p1+aIgJwotDOFq31nPOnKmvvSQ1aIHBCy+M7jxG8jCBMGoUs2frImXe2gAtWpTvQcycqQnnCy5QD+LAgejWVF6ypGR4ycMrzR0XgcjL0yE6jRrBxInRr4KDdtCRQkyhtp59tkasws1wjpZatXT+wt69KtRNmmjRwTfe0BBgtOW3jeRhP5FRoxg/Xu+Wf/Mbfd2qVfkexGef6fb004MVRcvLQ+zapecN9SBA747Hji05w7fK5OfDBx/AGWeoB/HaaxWOYUW6FuGKCtatC1deWfUEsucxtGwZFISLLipZeM9IXRIuECLSTkQ+E5EfRGShiFwXaL9bRNaKyJzA47RE22ZUbwoL4a234LTTdMYvaMdUnkB8+60W22vRQmfhpqWVLxChI5j8iMCf/hRV5Kd85szRTG52torD99/rPIdTT63wqSJdC6/UdzzwhCBpEwaNKpGMJHUB8H/Oudki0gCYJSIfB9570jn3WBJsMmoAX3yhE9f8E69atdKQUyScg+++C67nkJmpnX55AhFuBFPMcE7jME8+qRM6atfWYkWjRunCBxVdLDlAq1bhQ0xbtkCfPlW0OQKeBxFaaM+oHiRcIJxz64H1gee5IrIIyC77KMMonw8/1JXFvAJvEAyrOBc+XLJypY4M9VZlA427eyNvIrF0qZ7PX8AuJuzYAZdfDu+8o732X/6isaoYlCZt1UrLW+Tl6XUCvS7x9CBMIKo3Sc1BiEgHoA/g/TteIyLzROQVEWmSNMOMasmsWdqn1q0bbGvZUjvE3bvDH/Pdd7r11nUGzUPk5Oj60rm54Y9bskRLUtSpExPTlbVrtbjQP/4Bjzyi2fOrr45Z3epwcyH27NFyF/EaceXPQRjVj6QJhIjUByYD1zvndgHPA52B3qiH8XiE464QkZkiMnOzN8PHOOgpKtLwvH8mL5Q9gxg0/1C3bsnlLr31pQ89VAcLffNN6eOWLg2ff6g0K1fqLLP167VGyE03xXyYT7hyG/GuGeV5WKGrxRnVg6QIhIhkoOIwzjn3LoBzbqNzrtA5VwS8BISt0OKce9E51985179FUmspG1Xliiu0Y2reHG67rWrn+uknvdsPFYiyZhCDehBHHVWymujJJ+tSlk89pbWVXn215DHOhZ8DUWGc00luF14I3bppWdVPPoFBg6p44vB412LjRl2HoV8/9bogfh5Ey5bw8cdw6aXxOb8RX5IxikmAl4FFzrknfO3+OsS/AhYk2jYjcTgHb7+tYZpDDtHJbVXBK5NREQ8iL0+9Dn/+ATQHfOml8Ic/aG2ld97RMIzHpk2aKqhSgvrbb4Mz8/79b82sf/NNXCvX+T2I8eP1mo0apW3xvNcaNsxmTFdXkuFBHAtcBAwJGdL6iIjMF5F5wImAVWmpwWzcqJ3sJZdoTnb1ag3BV5bZs3WwT7duJdvLEogPP9TpBf78QygjR6qd//lPsM0r6uetg1whPv1Up3kfc4wu5fnMMxpWevHFkgsqxwG/B/H55xpWKyjQNlu/2QhHMkYxfQWEm37z70TbYiSPRYt0e+SRwXIO330XnOBWUWbP1tFHoSNAvTtjf4hp2zb4/e9h0iRNopbV0Q8dqucYPx7OOks71Kef1nRBhYaGFhRoHO3RR7WW9hNPqDLWr1+Bk1SNevX08fXXKsZejb+//EU9OcMIxWZSG0nBLxC9e+v8g2+/Db/vqlXBtRfC4S2FEBpeAhWMpk1LehA33ADvvQd33aWTksuqVpGeriueffCBehL/+Ifmk6OuQnrggCrRsceqOPzud5rhvuGGhIqDR6tW8NFH+vzEE1WQP/ssgetWGNUKq+ZqJIVFi7Quj7fIfb9+wSGnHjt3wn33abK4aVMdeuqN3/eTk6MltsMJBJScIPbNNzoHbcwYuPvu6GwdNQqefVY9hsxMLaD6y19G2DkvT2fsTZkC//ufzoTOzdUhUW++GSzUlCRattQlUQ85JMajsIwaiXkQRlJYtAiOOCI4eW3gQB32f+BAcJ+LL9aqEkOGqAcwYULp8+zfH1xvwFsXORSvxERhoSaes7Ph9tujt7V/fx1c1LChzsq+/voSa/GoC7NokZ68ZUud7fzssxpWuugiTWAsX550cYBgTubEE22hHqN8zIMwksKiRTq6xePoozUsP3euDjvdtAn+9S9drP6BBzQM9eSTuliaiIrJ//0fTJumx2dkRK591KqV3sg/8ogO6xw/voLRHecYcsR6Zr+4junT9jMwcxHcu16nYK9Zo57C+vVqxHnn6YikE04oOWMvRfALhGGUhwmEkRDy8nTE0vHHa/+5bl3JQSKY8fQAABC0SURBVDveUNNvv1WBmDRJ7/gvvFAF4frrdejpm2/q3fwbb+jN+h13aD/ctWv48BPofsuWaY74vPPKqbJaVKRq8tlnmqD44QdVs9xc0oBj/Ps2baqLHgwZoqOSfv3r0kutpRjeSKbBg5NqhlFNMIGoIUyfDq+8opGN9CT8qoWFcOON2qf6GT4crrlGIy2TJ8N//xuMffsFom1bfXz6qUZqxo/XUUnesNURIzRvcPHFmgcYMwZuvTW68fWtWql9J5ygq5iJoOGfrVvVC1ixQtccnTFDkxReRvuQQ1R5Ro3SeJg3aaN1a+1pQxdmrgaMGqXrMvzsZ8m2xKgWOOeq7aNfv37uYGHmTOfGjQv/3oEDzh1xhHPg3NtvV+1z8vKce+IJ59avr9hxL72kn9+3r3PHHKOPXr20rVEj3Y4apdujjtLtjz+WPMeYMdp+4426ffjhku+PG+fcZZc5t3x5lEZt3uzc22+7WWc/4C5o/l+3/fABzmVnO1e/vn5A6ONnP3Puwgude/1159atq9gFMIxqBDDTRdHHiu5bPenfv7+b6a1nmKJ8953esXXpUvlzzJ+vq0vm5uqEstC6Nk88ofH4hg01Dv/118H3NmzQIZ35+Tpq6NxzdSx8JJ5/Hq66SmP+06apNzJpko4oysrS8FBo/H77dvUKjjhCj/EnPz/5RMNAQ4fqGtEDB6q3U7u2ForzezuFhTrs8p//1NeR1j4upqhIJzVs2qRFhTZv1jGxCxdqXsCr2V2vnsatmjfXi9SokT6aN1dPoGNHvaWuwOpshlGdEZFZzrn+5e53MApE0Y5dvP3YSn59yl4ymjXUmgkxisssWaKTj5o00fxlly46LHLevOhGjezcqZVHPRFYs0Y71f37tW7/44/DH/8Y3H/DBu2cBw3SGkLXXacdcI8emtR98MGSlUyzs3W1M68Q3cCBQbuKijTsk5enE6kGDNDtqlXB40eN0sXM/Fx7LTz3nCaAe/cu+/tNnKg5gG7dQsJRzsH69exduZnTr+lAozr7ee/m71R9NmzQsE/oY+tWNTqUli214t7gwZqN7d+/0msoGEZNJFqBSHqYqCqPyoaYPn5mkQPnnuJaDS3Uq+fcsGHOPfmkxi8KC8s9x/79JXdbu1ZDKCLOdevm3Pbtzo0YEYxefPJJ+XYVFjo3YIBzDRo4N2eOczt2ONe9e/B1//4awvEzerRzGRkartm1y7mGDZ37+c+da99eP/ess5xbsMC5rVud+/xzPYc/qnLXXcFzffihto0b59zf/qbPe/dW27duDYZ+vvlG91+82LnTT9e2q67yGZWfrwcsX+7c99/rB//zn8698YbL//NfXKcm29yonrOcu+km50aOdK5fP/2SPsMKkZKG1qvnXKdOzh19tHO/+pVzV17p3Nixzj39tHMTJqiR8+ZpWMkwjDLBQkyRcbtyOWVYAdN/qM+Sh/9By8XTdNTKwoW6g4iGIrxwRFaWJiQzM9lVqzEPrhzBk8vO4LCGG3n45+8yc1tnHv7+JApcGhf2mMff5/eiS/NtLNjYgpuHzuS1GV05quMWPhw7Q+9uGzTQUs4hj5ffacRv7ziEenUKaVS/kM5t9/PtvHr85/FFDOuzlT9PbM0Nzx3Gope+4og2u/huYQOOvnkQt5y5mIdGzIXCQm78ey8e/283erfbwhNnf8uJP1utCdnCQigspCi/kDlrmnMgX3hhRh9en9uHv506mcu6T2fYxN+yeGtLVlx0Jxnkk7OjMe2yNpNWlA95eezeVUSXT5/nkIwtHFdnNs9tOYc6kscdjZ7h+rovUbsosPBCpMUXAmyjCZm1CqhXO1+vxxFHqKvVpQu0aaMhobp19dGokWaZkzDr2DBqKhZiKofFizUMM3o0vPRSoPGnnzjw4RSe/XdHnpl+FCe0XMT9P3uNNrKewv0FvLJqGHfkXMamgmacXf+/zMrryooCDZKfnfYeD8sYOhUsYTwjGMl42rGKxRzBI9zMPdzN37iMF7mCdAp4iDHUoogxPMR+MhnDQ/yOFziMpbzA7ziOr9hFI97gIi5CS52u5xCyWctY7uUu7uHnTGcdbfiRLtRnDwD7yOJrjuVEPiONMOEXH/mk80s+5CNOJo0CCknnwcy7GVPvGZ0J5j3S03VlnDp1GLf7TC5cehe1KOTyzp/ypz7/oGW9PcF969cPxvjLelTDEUCGUVMwgYiCG2/UBK9/uOXWrRreHjBAh8Onp2tBt507NR5/7LF6zIABmheYOFEXRTn22MAJioqgoIAPPyiifesCenbZz8Z1hRx6VAv27xc6tNpHQYFjzVadRNWmyT4yMwpZsak+Io6ZD3xM38Ny+X5lU1Zurc9Zx25WIwId8LAbe/HdDw1p3Syfn9Zk8eb9Kxn5y10lO3N/515WW61a7N4jPPcc7NqljtL115d9s+6cDqcdMKDkIjuGYVQfTCCiIDdXJ09t2BBsS0/XsfannqqTqx57TJPDtWrpCJtzzqlciYJXX9V861VXqYY8+6x2tldfrZ/5/PN6k37llWWf55tv4M9/1mO7d4c777SSCYZhVAwTCMMwDCMs0QqEFeszDMMwwmICYRiGYYTFBMIwDMMIiwmEYRiGERYTCMMwDCMsKScQInKKiPwoIj+JyJhk22MYhnGwklICISJpwLPAqUBXYISIdE2uVYZhGAcnKSUQwADgJ+fccufcAeAt4Mwk22QYhnFQkmorymUDq32v1wA/9+8gIlcAVwRe7haRHxNkWzQ0B7Yk24gySHX7wGyMBaluH6S+jaluH1TNxkOj2SnVBKJcnHMvAi8m245wiMjMaGYnJotUtw/MxliQ6vZB6tuY6vZBYmxMtRDTWqCd73XbQJthGIaRYFJNIP4HHCYiHUWkNnA+8H6SbTIMwzgoSakQk3OuQESuAT4C0oBXnHMLk2xWRUjJ0JePVLcPzMZYkOr2QerbmOr2QQJsrNbVXA3DMIz4kWohJsMwDCNFMIGoJCLSWETeEZHFIrJIRI4WkaYi8rGILA1smyTZxhtEZKGILBCRCSKSFcjvTA/MVJ8YyPUk0qZXRGSTiCzwtYW9bqI8HbB1noj0TZJ9jwZ+53ki8p6INPa9d2vAvh9F5OR42xfJRt97/yciTkSaB16nxDUMtF8buI4LReQRX3tKXEMR6S0i34nIHBGZKSIDAu3JuIbtROQzEfkhcL2uC7Qn9n/FOWePSjyA14HfBp7XBhoDjwBjAm1jgIeTaF82sAKoE3g9CRgd2J4faHsB+H2C7Toe6Ass8LWFvW7AacB/AAEGAtOTZN9wID3w/GGffV2BuUAm0BFYBqQlw8ZAezs0f7cSaJ5i1/BE4BMgM/C6ZapdQ2AKcKrvun2exGvYGugbeN4AWBK4Vgn9XzEPohKISCP0D+xlAOfcAefcDnTW9+uB3V4HzkqOhcWkA3VEJB2oC6wHhgDvBN5PuI3OuWnAtpDmSNftTOANp3wHNBaR1om2zzk3xTlXEHj5HTr82rPvLefcfufcCuAntBpAXIlwDQGeBG4G/InFlLiGwO+Bh5xz+wP7bPLZlyrX0AENA88bAet8Nib6Gq53zs0OPM8FFqE3fQn9XzGBqBwdgc3AqyLyvYj8TUTqAa2cc+sD+2wAWiXLQOfcWuAxYBUqDDuBWcAOX2e3Bv2jSzaRrlu4mfXJtvdS9E4NUsg+ETkTWOucmxvyVqrYeDgwKBDe/EJEjgq0p4p9ANcDj4rIavR/59ZAe1JtFJEOQB9gOgn+XzGBqBzpqHv6vHOuD7AHdfeKcer3JW2IWCA2eSYqZm2AesApybInWpJ93cpCRG4HCoBxybbFj4jUBW4D7ky2LWWQDjRFwx83AZNERJJrUil+D9zgnGsH3EAgQpBMRKQ+MBm43jm3y/9eIv5XTCAqxxpgjXNueuD1O6hgbPTcusB2U4TjE8EwYIVzbrNzLh94FzgWdT29+S+pMlM90nVLmZn1IjIaOB0YGfjHhNSxrzN6IzBXRHICdswWkUNIHRvXAO8GQiAzgCK0llCq2AcwCv0/AXibYKgrKTaKSAYqDuOcc55dCf1fMYGoBM65DcBqEekSaBoK/IDO+h4VaBsF/DMJ5nmsAgaKSN3AnZpn42fA2YF9km2jR6Tr9j5wcWCExkBgp8+9Thgicgoa2z/DObfX99b7wPkikikiHYHDgBmJts85N98519I518E51wHtjPsG/k5T4hoC/0AT1YjI4ejAji2kyDUMsA44IfB8CLA08Dzh1zDwP/sysMg594TvrcT+r8Q7G19TH0BvYCYwD/3jbwI0A6aif1ifAE2TbOM9wGJgAfB3dKRIJ/Qf8Cf0LikzwTZNQHMi+WhHdlmk64aOyHgWHdkyH+ifJPt+QuO7cwKPF3z73x6w70cCI2CSYWPI+zkERzGlyjWsDbwZ+FucDQxJtWsIHIfm6eai8f5+SbyGx6Hho3m+v7vTEv2/YjOpDcMwjLBYiMkwDMMIiwmEYRiGERYTCMMwDCMsJhCGYRhGWEwgDMMwjLCYQBgHDSLyJxEZFoPz7I6FPVVFRF4TkbPL39MwKkdKrShnGPHEOZfKpSgSioiku2BNLsMIi3kQRrVFRC4UkRmB+v1/FZG0QPtuEXkyUEd/qoi0CLQX33GLyEOBWvvzROSxQFsHEfk00DZVRNoH2juKyLciMl9E7gux4SYR+V/gmHsi2LlbRO4Xkbmi6w20CrXH2y+wHRwoaPdPEVkesHVk4LvOF5HOvtMPE127YImInB44Pk10DQvPrit95/1SRN5HZ9UbRpmYQBjVEhE5EjgPONY51xsoBEYG3q4HzHTOdQO+AO4KObYZ8Cugm3OuJ+B1+s8ArwfaxgFPB9qfQgsz9kBn33rnGY6WhhiAzqzvJyLHhzG3Hv/f3t27NhWFcRz/PgXBwZdBcHFQOgSdMkgL4iIUuggOoiC+DAqFioaCICK4+y8o1kkp6CYUMQEX37GoFcFFEHHUqVChtTWPw/NccxsuJHUp0d8HAifn5iRPh/Tccy/5HXjl7nXgCTDRx59YByaBfcAZoObuo8A00Ci9bk9+/mHghpltJn4VvODuI8AIMJExFhCZYVPuXuujBvnPaYKQQTUG7AfmzGw+nw/nsTZwL9t3idiCsgVgCbhtZkeBIl/pADCT7TulcQeJaIaivzCej3dEfMReYsLo9hOYzfYb4p96L3MeewIsE/EJrez/0DX+vru33f0T8DlrGCdyeeaJyIgdpbpee+y7INKT7kHIoDLibP9qz1d2RSK7+6rFdpJjRHDhRSKcre/3KNVw3d1v9hi74p1Mm190vner5EmamQ0ReUWF5VK7XXreZu33trsuz7oa7t5cU6zZISKaXqQvWkHIoHoMHDOznfBnr97deWyITmLtSeBZeWBm7G9394dE7n89D70ATmT7FPA028+7+gtN4Fy+H2a2q6inT1+IVRDAEWDTOsYWjpvZUN6XGCYC75rA+YyLxsxqFhtaiayLVhAykNz9o5ldA1p59r0CXCD2Y/4BjObxb8S9irKtwIO8Xm/ApexvELsEXiZ2DDyb/VPAjJldoRSP7u6tvBfyMtKZWQRO0/8+ILeyjvfAI/7u7P4rkc67DZh09yUzmyYuQ73N2OjvbPz2tzKAlOYq/xwzW3T3LRtdh8ig0yUmERGppBWEiIhU0gpCREQqaYIQEZFKmiBERKSSJggREamkCUJERCppghARkUq/ASgdmpjYOcWOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d54791ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_len = [np.average(episode_lengths[j-50:j]) for j in range(50,len(episode_lengths))]\n",
    "_ = plt.plot([x for x in range(50,201)],avg_len,'r', label='rolling average')\n",
    "_ = plt.plot([x for x in range(50,201)],episode_lengths[50:],'b', label='episode lengths')\n",
    "_ = plt.xlabel(\"episode number\")\n",
    "_ = plt.ylabel(\"episode length\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like its on its way - go play :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
